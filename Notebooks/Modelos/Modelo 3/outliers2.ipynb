{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# -----------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Otros objetivos\n",
    "# -----------------------------------------------------------------------\n",
    "import math\n",
    "\n",
    "# Gráficos\n",
    "# -----------------------------------------------------------------------\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys \n",
    "sys.path.append(os.path.abspath(\"../../../src\"))   \n",
    "import soporte_preprocesamiento as f\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Imputación de nulos usando métodos avanzados estadísticos\n",
    "# -----------------------------------------------------------------------\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler, RobustScaler\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# import plotly_express as px\n",
    "\n",
    "\n",
    "# Métodos estadísticos\n",
    "# -----------------------------------------------------------------------\n",
    "from scipy.stats import zscore # para calcular el z-score\n",
    "from sklearn.neighbors import LocalOutlierFactor # para detectar outliers usando el método LOF\n",
    "from sklearn.ensemble import IsolationForest # para detectar outliers usando el metodo IF\n",
    "from sklearn.neighbors import NearestNeighbors # para calcular la epsilon\n",
    "\n",
    "# Para generar combinaciones de listas\n",
    "# -----------------------------------------------------------------------\n",
    "from itertools import product, combinations\n",
    "pd.set_option(\"display.max_columns\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_escaldo=pd.read_csv(\"..\\..\\..\\datos\\datos0\\datos_clusterizados0_escalado.csv\", index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_escaldo.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Como ya vimos, nuestras columnas numéricas eran Sales_unitarios y Discount y solo Sales_unitarios cuenta con outliers por ello al ser la variable respuesta habrá que tener cuidado -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Dado que no tienen una distribución normal ninguna de ellas, no utilizaré el Z-Score ya que el porcentaje de fallo será demasiado alto. Por ello opto por el IQR -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicc_iqr=f.identificar_outliers_iqr(df_escaldo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Nos fijamos en que parece haber muy pocos Outliers -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicc_iqr[\"Sales_unitario\"].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- El número de outliers no es muy elevado (entorno al 6%) pero al tener sentido como ya se observaron en pasos anteirores voy a optar por no tocarlos  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contaminacion= [0.01, 0.05, 0.1]\n",
    "# estimadores = [100,400,1000, 2000] \n",
    "# combinaciones= list(product(contaminacion, estimadores))\n",
    "# for cont, esti in combinaciones:\n",
    "    \n",
    "#     ifo=IsolationForest(random_state=42, n_estimators=esti, contamination= cont, n_jobs=-1)         #n_estimator es el número de árboles y n_jobs con -1 coge todos los nucleos del ordenador\n",
    "\n",
    "#     df_escaldo[f\"outliers_ifo_{cont}_{esti}\"]=ifo.fit_predict(df_escaldo[[\"price\",\"size_MinMax\",\"distance_MinMax\"]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_min[\"outliers_ifo_0.01_100\"].value_counts(normalize=True)    #Esto nos muetsra como se acerca mucho al 1% de outliers por el nivel de contaminación ser 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_min.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columnas_hue=df_min.filter(like=\"outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_min.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "A pesar de que teóricamente el IFO por las carcaterísticas de los datos parece ser la mejor opción y tras haber observado que marca outliers en los precios ma´s bajo. Pasamos ahora a identificar los outliers con la metodología LOF.\n",
    "\n",
    "Para poder comparar más fácil voy a sacar IFO y LOF juntos. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista_contaminaciones = [0.01, 0.05, 0.1]\n",
    "# lista_neighbors = [8,20, 50]\n",
    "\n",
    "# combinaciones = list(product(lista_contaminaciones, lista_neighbors))\n",
    "# combinaciones\n",
    "\n",
    "\n",
    "# for cont, neighbors in tqdm(combinaciones):\n",
    "#     lof = LocalOutlierFactor(n_neighbors=neighbors,\n",
    "#                             contamination=cont,\n",
    "#                             n_jobs=-1)\n",
    "\n",
    "#     df_min[f\"outliers_lof_{cont}_{neighbors}\"] = lof.fit_predict(df_min[[\"price\",\"size_MinMax\",\"distance_MinMax\"]])\n",
    "#     y_pred = lof.fit_predict(df_min[[\"price\",\"size_MinMax\",\"distance_MinMax\"]])\n",
    "# df_min\n",
    "\n",
    "# # #visualizacion\n",
    "# # columnas_hue = df_min.filter(like=\"outlier\").columns\n",
    "\n",
    "# # combinaciones_viz = list(combinations([\"price\",\"size_MinMax\",\"distance_MinMax\"], 2))\n",
    "# # combinaciones_viz\n",
    "\n",
    "# # for outlier in tqdm(columnas_hue):\n",
    "# #     fig, axes = plt.subplots(nrows=1, ncols=3, figsize = (15, 5))\n",
    "# #     axes = axes.flat\n",
    "\n",
    "# #     for indice, tupla in enumerate(combinaciones_viz):\n",
    "# #         sns.scatterplot(x = tupla[0],\n",
    "# #                         y = tupla[1],\n",
    "# #                         ax = axes[indice],\n",
    "# #                         data = df_min,\n",
    "# #                         hue=outlier,\n",
    "# #                         palette=\"Set1\",\n",
    "# #                         style=outlier,\n",
    "# #                         alpha=0.5)\n",
    "        \n",
    "# #     plt.suptitle(outlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Lo que saco en claro es que el nivel de contaminación más estricto (10%) es la mejor opción porque es el que más se acerca a la realidad de los datos.  \n",
    "\n",
    "Tras observar los gráficos del LOF observo que en el caso del tamaño, se consideran outliers aquellas viviendas que cuentan con un alto precio y según van aumentando su tamaño se va reduciendo el número de outliers. Por otro lado, al  observar la distancia nos percatamos de que de nuevo los outliers se concentran en los precios más altos lo que en un principio parece no tener sentido pues se mantienen aproximadamente igual distribuidos a lo largo de las distintas distancias. Sin embargo, no nos podemos fiar porque puede que esos datos sean outliers por otras variables que no sea la distancia.\n",
    "\n",
    "Por el momento, me parece más adecuado hacer uso de la metodología IFO. -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_min.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ifo=df_min[['price', 'propertyType', 'exterior', 'rooms', 'bathrooms', 'province',\n",
    "#        'municipality', 'status', 'newDevelopment', 'floor', 'district',\n",
    "#        'hasLift', 'parkingSpace', 'size_MinMax', 'distance_MinMax',\n",
    "#        'outliers_ifo_0.01_100', 'outliers_ifo_0.01_400',\n",
    "#        'outliers_ifo_0.01_1000', 'outliers_ifo_0.01_2000',\n",
    "#        'outliers_ifo_0.05_100', 'outliers_ifo_0.05_400',\n",
    "#        'outliers_ifo_0.05_1000', 'outliers_ifo_0.05_2000',\n",
    "#        'outliers_ifo_0.1_100', 'outliers_ifo_0.1_400', 'outliers_ifo_0.1_1000',\n",
    "#        'outliers_ifo_0.1_2000']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ifo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Ahora me quito las que tengan todas las filas con 1 y así me quedo con todas las que al menos tienen un Outlier -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columnasdf=df_min.filter(like=\"outliers_ifo\")\n",
    "# columnas_ifo=columnasdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# filtered_df = df_ifo[(df_ifo[columnas_ifo] == -1).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Al observar las filas que tienen todos los valores con -1 y observar que suponen una parte ínfima de los datos, se decide eliminarlos -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_result = df_ifo.drop(index = filtered_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_result.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Ahora seleccionamos el 60% de los outliers -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proporcion = 0.6 * len(columnas_ifo)\n",
    "# df_outliers_60 = df_result[df_result[columnas_ifo].eq(-1).sum(axis=1) >= proporcion]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ifo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outliers_60.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Observamos la distancia -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outliers_60[\"distance_MinMax\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outliers_60[df_outliers_60[\"distance_MinMax\"] > 0.9][\"distance_MinMax\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outliers_60[df_outliers_60[\"distance_MinMax\"] > 0.9][\"distance_MinMax\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outliers_60[df_outliers_60[\"distance_MinMax\"] > 0][\"distance_MinMax\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Estamos observando los valores mayores a 0.9 (aproximadamente a partir de 55 kilometros del centro) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outliers_60.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outliers_60[\"distance_MinMax\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outliers_60[\"distance_MinMax\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outliers_60[df_outliers_60[\"distance_MinMax\"] > 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outliers_60[\"distance_MinMax\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Aqui quiero crear el intervalo de outliers con el que me voy a quedar.  \n",
    "Dado que las viviendas con un valor de distancia mayor a 0.9 (unos 55km aproximadamente del centro) me las marca por lo general como outliers y dado que no hay muchas se eliminan, para el resto se tratará de imputar su valor. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outliers_60=df_outliers_60[(df_outliers_60[\"distance_MinMax\"] > 0 ) & (df_outliers_60[\"distance_MinMax\"] < 0.9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Casi la mitad de otliers se encuentra entre 0.9 y 1 (55 y 60 kilometros de distancia aproximadamente). Esto muestra que hay otra mitad de viviendas (outliers) entre los 0 km y los 55 km aproximadamente cosa que tiene sentido con lo que no puedo eliminar estos outliers.El resto si que no tiene sentido mantenerlos (>0.9) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Ahora observamos los tamaños -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outliers_60[\"size_MinMax\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outliers_60[\"size_MinMax\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "En los outliers de size: media(0.47) y mediana (0.39) indica que en los outliers hay valores atípicos que distorsionan la media (Ej:1 o 0.85271318)  \n",
    "En los outliers de distance: media(0.52) y mediana (0.57) indica que en los outliers hay valores atípicos que distorsionan la media (Ej:0.00739922 o 0.00980983)   -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.float_format = \"{:,.2f}\".format \n",
    "# df_outliers_60.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outliers_60[df_outliers_60[\"size_MinMax\"] < 0.35][\"size_MinMax\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outliers_60[df_outliers_60[\"size_MinMax\"] < 0.35].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outliers_60[df_outliers_60[\"size_MinMax\"] < 0.35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outliers_60[df_outliers_60[\"size_MinMax\"] > 0.35].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outliers_60[df_outliers_60[\"size_MinMax\"] > 0.35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Aqui quiero crear el intervalo de outliers con el que me voy a quedar de size  \n",
    "Dado que las viviendas con un valor de size menor a 0.35 (75 metros cuadrados aproximadamente) y mayor a 0.84 (135 metros cuadrados aproximadamente) me las marca por lo general como outliers y dado que no hay muchas se eliminan, para el resto se tratará de imputar su valor. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outliers_60=df_outliers_60[(df_outliers_60[\"size_MinMax\"] > 0.35 ) & (df_outliers_60[\"size_MinMax\"] < 0.84)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_outliers_60.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Ahora a que ya hemos analizado los outliers decidimos imputarlos usando KNN con lo que primero pasamos todos a nan y los meto en el dataframe completo donde voy a querer meter el imputer KNN (y probaremos con el iterative también) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_result.loc[df_outliers_60.index, \"size_MinMax\"] = np.nan\n",
    "# df_result.loc[df_outliers_60.index, \"distance_MinMax\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_numericas=df_result.select_dtypes(include=np.number)\n",
    "# imputer_knn= KNNImputer(n_neighbors=5)   #por defecto siempre lo calcula en base a la media y no se puede cambiar\n",
    "# knn_imputado= imputer_knn.fit_transform(df_numericas)    #como es solo para numericas se tiene que meter el df de numericas pero hay que definirlo otra vez porque hemos dropeado duplicados\n",
    "# df_knn=df_result.copy()\n",
    "# df_num_sin_nulos=pd.DataFrame(knn_imputado, columns= df_numericas.columns)  #para que tenga los mismo nombres de columnas\n",
    "# df_knn[df_numericas.columns]= df_num_sin_nulos    #Con esto metemos todo el dataframe de las numericas sin nulos donde corresponda rellenando esos nulos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_knn.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_knn.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_knn.to_csv(\"../../datos/datos1/datos_sin_outliers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv(\"../../datos/datos1/datos_sin_outliers.csv\", index_col=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filt=df[[\"price\", \"size_MinMax\", \"distance_MinMax\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.plot_outliers_univariados(df_filt, \"b\", (15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_est_con3=df_min[[\"price\", \"size_MinMax\", \"distance_MinMax\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df_filt[\"size_MinMax\"]> 0.8).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df_est_con3[\"size_MinMax\"]> 0.8).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df_filt[\"price\"]< 510).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df_est_con3[\"price\"]< 510).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.plot_outliers_univariados(df_est_con3, \"b\", (15,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- caso con iterative -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_numericas=df_result.select_dtypes(include=np.number)\n",
    "# df_numericas.drop(columns=\"price\", inplace=True)\n",
    "# imputer_iterative= IterativeImputer()       #Aquí se puede poner el KNNImputer o el RandomForestRegressor\n",
    "#                                             #missing values es por si los nulos no estan como np.nan sino en texto por ejemplo (aunque lo suyo es limpiarlo en el EDA)\n",
    "#                                             #initial_strategy= \"median\" sirve para indicar que me lo haga con las medianas\n",
    "# iterative_imputado=imputer_iterative.fit_transform(df_numericas)   #como es solo para numericas se tiene que meter el df de numericas pero hay que definirlo otra vez porque hemos dropeado duplicados\n",
    "# df_iterativo=df_result.copy()\n",
    "# df_num_sin_nulos=pd.DataFrame(iterative_imputado, columns= df_numericas.columns)  #para que tenga los mismo nombres de columnas\n",
    "# df_iterativo[df_numericas.columns]= df_num_sin_nulos    #Con esto metemos todo el dataframe de las numericas sin nulos donde corresponda rellenando esos nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_iterativo.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_iterativo.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_iterativo.to_csv(\"../../datos/datos1/datos_sin_outliers_iterativo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_it=pd.read_csv(\"../../datos/datos1/datos_sin_outliers_iterativo.csv\", index_col=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filt_it=df_it[[\"price\", \"size_MinMax\", \"distance_MinMax\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.plot_outliers_univariados(df_filt_it, \"b\", (15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_est_con3=df_min[[\"price\", \"size_MinMax\", \"distance_MinMax\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df_filt_it[\"size_MinMax\"]> 0.8).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df_est_con3[\"size_MinMax\"]> 0.8).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df_filt_it[\"price\"]< 510).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df_est_con3[\"price\"]< 510).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.plot_outliers_univariados(df_est_con3, \"b\", (15,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Ya están tratados -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Observamos que no hay diferencias muy significativas entre imputar con KNN o con ITERATIVE pero tras observar que el iterative reduce la dispersión entre la media y la mediana de size y que el KNN aumenta la desviación típica (variabilidad) en la distancia, nos decantamos finalmente por el uso del ITERATIVE -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entorno_proyecto9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
